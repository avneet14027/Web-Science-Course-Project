{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from string import punctuation\n",
    "import torch.nn.functional as F\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"dataset/web_science_dataset.jsonl\"\n",
    "json_data = []\n",
    "with open(filename) as f:\n",
    "    json_data = f.readlines()\n",
    "json_data_list = []\n",
    "for item in json_data:\n",
    "    json_data_list.append(json.loads(item))\n",
    "df_ = pd.DataFrame(json_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(957, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv',delimiter=\",\")\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer URL</th>\n",
       "      <th>Answer Label</th>\n",
       "      <th>Question Rating</th>\n",
       "      <th>Answer Quality</th>\n",
       "      <th>Factual</th>\n",
       "      <th>questionId</th>\n",
       "      <th>answer</th>\n",
       "      <th>categoryId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>does water have a memory as claimed in homeopathy</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2#27</td>\n",
       "      <td>no</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>No\\n\\nWater forms strong intermolecular forces...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>does chamomile help you to relax</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/3...</td>\n",
       "      <td>na</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>There is a website by the NIH about Chamomile ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>are there benefits to the eca stack for bodybu...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>It appears that the combination of ephedrine a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>can positive thinking provide an improved outc...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>To add to Krzysztof's answer. There were also ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>are vegetables good for me</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/3...</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>\\n  From a young age, most people are told tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  does water have a memory as claimed in homeopathy   \n",
       "1                   does chamomile help you to relax   \n",
       "2  are there benefits to the eca stack for bodybu...   \n",
       "3  can positive thinking provide an improved outc...   \n",
       "4                         are vegetables good for me   \n",
       "\n",
       "                                          Answer URL Answer Label  \\\n",
       "0  https://skeptics.stackexchange.com/questions/2#27           no   \n",
       "1  https://skeptics.stackexchange.com/questions/3...           na   \n",
       "2  https://skeptics.stackexchange.com/questions/2...          yes   \n",
       "3  https://skeptics.stackexchange.com/questions/2...          yes   \n",
       "4  https://skeptics.stackexchange.com/questions/3...          yes   \n",
       "\n",
       "   Question Rating  Answer Quality  Factual  questionId  \\\n",
       "0         1.666667        2.333333        1           2   \n",
       "1         2.000000        2.000000        1           3   \n",
       "2         1.666667        2.000000        1          22   \n",
       "3         2.666667        2.666667        1          26   \n",
       "4         2.000000        2.333333        1          32   \n",
       "\n",
       "                                              answer  categoryId  \n",
       "0  No\\n\\nWater forms strong intermolecular forces...           3  \n",
       "1  There is a website by the NIH about Chamomile ...           0  \n",
       "2  It appears that the combination of ephedrine a...           0  \n",
       "3  To add to Krzysztof's answer. There were also ...           2  \n",
       "4  \\n  From a young age, most people are told tha...           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_ = dict(zip(df_['questionId'].astype(int),df_['answer']))\n",
    "df['answer'] = df['questionId'].map(map_)\n",
    "\n",
    "map_cat = dict(zip(df_['questionId'].astype(int),df_['categoryId']))\n",
    "df['categoryId'] = df['questionId'].map(map_cat)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1328.0\n",
       "1       599.0\n",
       "2      1912.0\n",
       "3      2044.0\n",
       "4      2535.0\n",
       "        ...  \n",
       "952    2051.0\n",
       "953    2216.0\n",
       "954     404.0\n",
       "955    3757.0\n",
       "956    1149.0\n",
       "Name: answer, Length: 957, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['answer'].apply(lambda x: np.mean(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return (' '.join(lemmatizer.lemmatize(w) for w in word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):    \n",
    "\n",
    "    # remove leading/trailing spaces\n",
    "    df = df.str.strip()\n",
    "    \n",
    "    # convert to lowercase\n",
    "    df = df.str.lower()\n",
    "    \n",
    "    df = df.replace(to_replace ='http\\S+', value = '', regex = True)\n",
    "    \n",
    "    # remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    df = df.str.translate(translator)\n",
    "    \n",
    "    # remove non-alphanumeric characters\n",
    "    df = df.replace(to_replace ='\\s*[^A-Za-z0-9]+\\s*', value = ' ', regex = True)\n",
    "    \n",
    "    # remove digits\n",
    "    translator = str.maketrans('', '', string.digits) \n",
    "    df = df.str.translate(translator)\n",
    "    \n",
    "    df = df.str.strip()\n",
    "    \n",
    "    #lemmatize\n",
    "    #df = df.apply(lemmatize_text)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case, remove leading/trailing spaces\n",
    "df['Question'] = df['Question'].astype(str).str.lower().str.strip()\n",
    "df['Answer Label'] = df['Answer Label'].astype(str).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['na' 'no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "df['Question'] = preprocess_text(df['Question'])\n",
    "df['answer'] = preprocess_text(df['answer'])\n",
    "print(np.unique(df['Answer Label']))\n",
    "df['Answer Label'] = df['Answer Label'].replace('nan','na')\n",
    "\n",
    "answer_label_map = {'yes':2,'no':0,'na':1}\n",
    "df['Answer Label'] = df['Answer Label'].map(answer_label_map)\n",
    "#df['Answer Quality'] = ((df['Answer Quality']-1)/(3-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      799.0\n",
       "1      344.0\n",
       "2      895.0\n",
       "3      726.0\n",
       "4      741.0\n",
       "       ...  \n",
       "952    837.0\n",
       "953    777.0\n",
       "954    260.0\n",
       "955    741.0\n",
       "956    841.0\n",
       "Name: answer, Length: 957, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    text = remove_stopwords(row['answer'])\n",
    "    #print(text)\n",
    "    new_text = \" \".join(text.split(\" \")[:100])\n",
    "    #print(new_text)\n",
    "    df.at[i,'answer'] = new_text\n",
    "\n",
    "mean_answer_lengths = df['answer'].apply(lambda x: np.mean(len(x)))\n",
    "mean_answer_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer URL</th>\n",
       "      <th>Answer Label</th>\n",
       "      <th>Question Rating</th>\n",
       "      <th>Answer Quality</th>\n",
       "      <th>Factual</th>\n",
       "      <th>questionId</th>\n",
       "      <th>answer</th>\n",
       "      <th>categoryId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>does water have a memory as claimed in homeopathy</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2#27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>water forms strong intermolecular forces molec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>does chamomile help you to relax</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/3...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>website nih chamomile listing evidence effecti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>are there benefits to the eca stack for bodybu...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>appears combination ephedrine caffeine positiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>can positive thinking provide an improved outc...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>add krzysztofs answer studies suggesting peopl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>are vegetables good for me</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>young age people told vegetables good eat vege...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  does water have a memory as claimed in homeopathy   \n",
       "1                   does chamomile help you to relax   \n",
       "2  are there benefits to the eca stack for bodybu...   \n",
       "3  can positive thinking provide an improved outc...   \n",
       "4                         are vegetables good for me   \n",
       "\n",
       "                                          Answer URL  Answer Label  \\\n",
       "0  https://skeptics.stackexchange.com/questions/2#27             0   \n",
       "1  https://skeptics.stackexchange.com/questions/3...             1   \n",
       "2  https://skeptics.stackexchange.com/questions/2...             2   \n",
       "3  https://skeptics.stackexchange.com/questions/2...             2   \n",
       "4  https://skeptics.stackexchange.com/questions/3...             2   \n",
       "\n",
       "   Question Rating  Answer Quality  Factual  questionId  \\\n",
       "0         1.666667        2.333333        1           2   \n",
       "1         2.000000        2.000000        1           3   \n",
       "2         1.666667        2.000000        1          22   \n",
       "3         2.666667        2.666667        1          26   \n",
       "4         2.000000        2.333333        1          32   \n",
       "\n",
       "                                              answer  categoryId  \n",
       "0  water forms strong intermolecular forces molec...           3  \n",
       "1  website nih chamomile listing evidence effecti...           0  \n",
       "2  appears combination ephedrine caffeine positiv...           0  \n",
       "3  add krzysztofs answer studies suggesting peopl...           2  \n",
       "4  young age people told vegetables good eat vege...           0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.readlines()\n",
    "        data = [int(i.strip()) for i in data ]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = read_file('quality_prediction_data/training_ids.txt')\n",
    "test_ids = read_file('quality_prediction_data/testing_ids.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.loc[df['questionId'].isin(train_ids)]\n",
    "test_data = df.loc[df['questionId'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer URL</th>\n",
       "      <th>Answer Label</th>\n",
       "      <th>Question Rating</th>\n",
       "      <th>Answer Quality</th>\n",
       "      <th>Factual</th>\n",
       "      <th>questionId</th>\n",
       "      <th>answer</th>\n",
       "      <th>categoryId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>is this description of the processes which tak...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>28612</td>\n",
       "      <td>lets run list recommended daily intake sugar w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905</td>\n",
       "      <td>does heads up texas holdem have more possible ...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/4...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>43220</td>\n",
       "      <td>according superhuman ai headsup nolimit poker ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>do saunas affect your health</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/4...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>4996</td>\n",
       "      <td>benefits listed sentence detoxification negati...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>862</td>\n",
       "      <td>is climate change causing jellyfish to wash up...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/3...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>39904</td>\n",
       "      <td>articles ive climate change factor contributed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>does honey ever go bad</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/7...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>7247</td>\n",
       "      <td>common knowledge sugar help microorganism grow...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "713  is this description of the processes which tak...   \n",
       "905  does heads up texas holdem have more possible ...   \n",
       "196                       do saunas affect your health   \n",
       "862  is climate change causing jellyfish to wash up...   \n",
       "286                             does honey ever go bad   \n",
       "\n",
       "                                            Answer URL  Answer Label  \\\n",
       "713  https://skeptics.stackexchange.com/questions/2...             1   \n",
       "905  https://skeptics.stackexchange.com/questions/4...             2   \n",
       "196  https://skeptics.stackexchange.com/questions/4...             0   \n",
       "862  https://skeptics.stackexchange.com/questions/3...             2   \n",
       "286  https://skeptics.stackexchange.com/questions/7...             0   \n",
       "\n",
       "     Question Rating  Answer Quality  Factual  questionId  \\\n",
       "713         2.333333        3.000000        1       28612   \n",
       "905         2.000000        2.666667        1       43220   \n",
       "196         2.000000        2.500000        1        4996   \n",
       "862         2.333333        2.333333        1       39904   \n",
       "286         2.666667        2.666667        1        7247   \n",
       "\n",
       "                                                answer  categoryId  \n",
       "713  lets run list recommended daily intake sugar w...           0  \n",
       "905  according superhuman ai headsup nolimit poker ...           3  \n",
       "196  benefits listed sentence detoxification negati...           2  \n",
       "862  articles ive climate change factor contributed...           1  \n",
       "286  common knowledge sugar help microorganism grow...           0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data = train_test_split(df,stratify=df['categoryId'].values, test_size=0.2)\n",
    "train_data.shape\n",
    "valid_data.shape\n",
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = set(train_data['Answer Label'])\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {v:k for k,v in enumerate(unique_labels)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import tokenize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = \"C:\\\\Users\\\\Reen\\\\Desktop\\\\web science\\\\WordEmbeddings\\\\GoogleNews-vectors-negative300.bin.gz\"\n",
    "word_to_vec_model = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True,limit=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = np.concatenate([word_to_vec_model.vectors, np.zeros(shape=(1,300))], axis=0) #last vector padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1000\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "num_labels = len(label_map)\n",
    "batch_size = 64\n",
    "lr = 2e-4\n",
    "lstm_dim = 20\n",
    "n_epochs = 20\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDatasetReader():\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        row = self.df.values[idx]\n",
    "        input_seq,seq_lens = text_to_batch_bilstm([row[7]]) #sending a list of one row\n",
    "        label = row[2]\n",
    "        return input_seq, seq_lens, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch_bilstm(input_data: Tuple) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    input_ids = [i[0][0] for i in input_data]\n",
    "    seq_lens = [i[1][0] for i in input_data]\n",
    "    labels = [i[2] for i in input_data]\n",
    "\n",
    "    max_length = max([len(i) for i in input_ids])\n",
    "\n",
    "    input_ids = [(i + [50000] * (max_length - len(i))) for i in input_ids]\n",
    "\n",
    "    assert (all(len(i) == max_length for i in input_ids))\n",
    "    return torch.tensor(input_ids), torch.tensor(seq_lens), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_batch_bilstm(text: List) -> Tuple[List, List]:\n",
    "    oov_word_token = 500000 #oov token\n",
    "    \n",
    "    sentences = []\n",
    "    for t in text:\n",
    "        t = t.lower()\n",
    "        t = ''.join([c for c in t if c not in punctuation])\n",
    "    sentences.append(t)\n",
    "        \n",
    "    tokens = [ list(tokenize(t)) for t in sentences]\n",
    "    #print(tokens)\n",
    "    \n",
    "    input_ids = [[word_to_vec_model.vocab[token].index for token in sentence if token in word_to_vec_model] for sentence in tokens]\n",
    "    #print(input_ids)\n",
    "    \n",
    "    #input_ids = [tokenizer.encode_ids_with_eos(t) for t in text]\n",
    "\n",
    "    return input_ids, [len(ids) for ids in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 9)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataset readers and read data\n",
    "train_dataset = ClassificationDatasetReader(train_data)\n",
    "train_dl = DataLoader(train_dataset, batch_size=len(train_data), shuffle=True, collate_fn=collate_batch_bilstm)\n",
    "\n",
    "valid_dataset = ClassificationDatasetReader(valid_data)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=len(valid_data), collate_fn=collate_batch_bilstm)\n",
    "\n",
    "test_dataset = ClassificationDatasetReader(test_data)\n",
    "test_dl = DataLoader(test_dataset, batch_size=len(test_data), collate_fn=collate_batch_bilstm)\n",
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class LSTMNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_embeddings: torch.tensor, lstm_dim: int, dropout_prob: float = 0.1, n_classes: int = 5):\n",
    "        \n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        \n",
    "        #LSTM input\n",
    "        self.input_size = pretrained_embeddings.shape[1] #features in input\n",
    "        self.hidden_size = 200 \n",
    "        self.num_layers = 1 #default \n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1)\n",
    "        self.lstm = nn.LSTM(self.input_size,self.hidden_size,self.num_layers,batch_first=True,dropout=dropout_prob,bidirectional=True)\n",
    "        self.ff = nn.Linear(2*self.hidden_size,n_classes)\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "    def forward(self, inputs, input_lens, labels = None):\n",
    "        \n",
    "        # Get embeddings (b x sl x edim)\n",
    "        embeds = self.embeddings(inputs)\n",
    "        lstm_out, hidden = self.lstm(embeds)\n",
    "        \n",
    "        # Get the last output for classification (b x 2*lstm_dim)\n",
    "        ff_in = lstm_out.gather(1, input_lens.view(-1,1,1).expand(lstm_out.size(0), 1, lstm_out.size(2)) - 1).squeeze()\n",
    "        #print(input_lens.view(-1,1,1).expand(lstm_out.size(0), 1, lstm_out.size(2)))\n",
    "        \n",
    "        # Get logits (b x 2)\n",
    "        logits = self.ff(ff_in).view(-1, self.n_classes)\n",
    "        \n",
    "        outputs = (logits,)\n",
    "        if labels is not None:\n",
    "            # Xentropy loss\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = LSTMNetwork(\n",
    "    pretrained_embeddings=torch.FloatTensor(pretrained_embeddings), \n",
    "    lstm_dim=lstm_dim, \n",
    "    dropout_prob=0, \n",
    "    n_classes=len(label_map)\n",
    "  ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, labels):\n",
    "    return torch.sum(torch.argmax(logits, dim=-1) == labels).type(torch.float) / float(labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, valid_dl, optimizer, n_epochs, device):\n",
    "    \n",
    "    losses = []\n",
    "    best_acc = 0.0\n",
    "  \n",
    "    for ep in range(n_epochs):\n",
    "        loss_epoch = []\n",
    "        \n",
    "        for batch in tqdm(train_dl):\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids = batch[0]\n",
    "            seq_lens = batch[1]\n",
    "            labels = batch[2]\n",
    "\n",
    "            loss, logits = model(input_ids, seq_lens, labels=labels)\n",
    "            losses.append(loss.item())\n",
    "            loss_epoch.append(loss.item())\n",
    "      \n",
    "            #print(loss.dtype)\n",
    "            loss.backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "        #gc.collect()\n",
    "    \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_dl:\n",
    "\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids = batch[0]\n",
    "                seq_lens = batch[1]\n",
    "                labels = batch[2]\n",
    "\n",
    "                val_loss, logits = model(input_ids, seq_lens, labels=labels)\n",
    "                acc = accuracy(logits, labels)\n",
    "\n",
    "                print(f'Validation accuracy: {acc}, train loss: {sum(loss_epoch) / len(loss_epoch)}',\"val_loss: \",val_loss.item())\n",
    "                best_model = model.state_dict()\n",
    "\n",
    "                if acc > best_acc:\n",
    "                  #best_model = model.state_dict()\n",
    "                    best_acc = acc\n",
    "                #gc.collect()\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23f3016e60b43e1bd7b73550cf945dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.3958333432674408, train loss: 1.0959408283233643 val_loss:  1.0925304889678955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3d4a6d836743fe8a78e8ec7d2e1bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.4010416865348816, train loss: 1.0944340229034424 val_loss:  1.0913115739822388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac45eed733c4d1885c881bffa15e3f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.4166666865348816, train loss: 1.0929973125457764 val_loss:  1.0901834964752197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0c975bd1f34048957e4c27542348ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.4114583432674408, train loss: 1.091625690460205 val_loss:  1.0891424417495728\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6dbde7689c4e06bc3b7fff932bc041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.40625, train loss: 1.090315341949463 val_loss:  1.0881855487823486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af981c1103147fa88d408ee5deec000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.3958333432674408, train loss: 1.0890611410140991 val_loss:  1.087310552597046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310931860fdc43b4bba0419f4940a5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.3958333432674408, train loss: 1.0878580808639526 val_loss:  1.0865134000778198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd9161bfd294814ae5a23842d0efd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.390625, train loss: 1.0867005586624146 val_loss:  1.0857908725738525\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b3020db0134f12802601fdedcf2c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.3958333432674408, train loss: 1.0855833292007446 val_loss:  1.0851398706436157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae294df2794452d87649e177c8f7cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.375, train loss: 1.0844999551773071 val_loss:  1.084555745124817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2cc138e49e46f68760e4cc68221e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.375, train loss: 1.083444595336914 val_loss:  1.0840353965759277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba482b00c6f41bda703acee7030edec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.3802083432674408, train loss: 1.082411527633667 val_loss:  1.083574652671814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d436101f3324c678a7fcbe726600e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.3645833432674408, train loss: 1.0813931226730347 val_loss:  1.083168387413025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761ff6b622fd4372a098bad0fbead5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.359375, train loss: 1.0803834199905396 val_loss:  1.0828124284744263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4decf2c58a3340d2a8d932d34bf7d31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.359375, train loss: 1.0793747901916504 val_loss:  1.0825012922286987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef094134bda4c7fa4be06ac341dc319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.3697916865348816, train loss: 1.078360915184021 val_loss:  1.082229733467102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5e5841bff64e3ea8774b8758f57537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.3645833432674408, train loss: 1.077335000038147 val_loss:  1.081992506980896\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea749b5496f45b8a01532b887a74f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.359375, train loss: 1.0762903690338135 val_loss:  1.0817841291427612\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468c1baa5bb04b80b609a01de661f280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.3697916865348816, train loss: 1.0752224922180176 val_loss:  1.0815997123718262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b590d7211d4feb9417112b5cd6fbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.375, train loss: 1.0741257667541504 val_loss:  1.0814348459243774\n"
     ]
    }
   ],
   "source": [
    "# Create the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Train\n",
    "model, losses = train(model, train_dl, valid_dl, optimizer, n_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
