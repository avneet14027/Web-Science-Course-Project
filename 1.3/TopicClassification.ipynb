{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'medical-science': 2,\n",
       " 'nutrition': 0,\n",
       " 'psychology': 4,\n",
       " 'climate-change': 1,\n",
       " 'physics': 3}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"dataset/web_science_dataset.jsonl\"\n",
    "json_data = []\n",
    "with open(filename) as f:\n",
    "    json_data = f.readlines()\n",
    "json_data_list = []\n",
    "for item in json_data:\n",
    "    json_data_list.append(json.loads(item))\n",
    "df = pd.DataFrame(json_data_list)\n",
    "\n",
    "#labels\n",
    "label_map = dict(zip(df['category'],df['categoryId']))\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return (' '.join(lemmatizer.lemmatize(w) for w in word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):    \n",
    "\n",
    "    # remove leading/trailing spaces\n",
    "    df = df.str.strip()\n",
    "    \n",
    "    # convert to lowercase\n",
    "    df = df.str.lower()\n",
    "    \n",
    "    #df = df.replace(to_replace ='http\\S+', value = '', regex = True)\n",
    "    \n",
    "    # remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    df = df.str.translate(translator)\n",
    "    \n",
    "    # remove non-alphanumeric characters\n",
    "    df = df.replace(to_replace ='\\s*[^A-Za-z0-9]+\\s*', value = ' ', regex = True)\n",
    "    \n",
    "    # remove digits\n",
    "    translator = str.maketrans('', '', string.digits) \n",
    "    df = df.str.translate(translator)\n",
    "    \n",
    "    df = df.str.strip()\n",
    "    \n",
    "    #lemmatize\n",
    "    df = df.apply(lemmatize_text)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>questionId</th>\n",
       "      <th>questionUrl</th>\n",
       "      <th>category</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>answer</th>\n",
       "      <th>answerUrl</th>\n",
       "      <th>answerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>can headbanging cause brain damage</td>\n",
       "      <td>14138</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/1...</td>\n",
       "      <td>medical-science</td>\n",
       "      <td>2</td>\n",
       "      <td>A number of injuries have been attributed to t...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/1...</td>\n",
       "      <td>14139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>doe the shangrila diet work according to it su...</td>\n",
       "      <td>10103</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/1...</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0</td>\n",
       "      <td>The Shangri-La diet depends on two theories:\\n...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/1...</td>\n",
       "      <td>16121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>can phobia be genetic but created in one gener...</td>\n",
       "      <td>18713</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/1...</td>\n",
       "      <td>psychology</td>\n",
       "      <td>4</td>\n",
       "      <td>This question has remained unanswered yet not ...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/1...</td>\n",
       "      <td>22322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>do of u american think that global warming is ...</td>\n",
       "      <td>36010</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/3...</td>\n",
       "      <td>climate-change</td>\n",
       "      <td>1</td>\n",
       "      <td>The&amp;nbsp;40% figure most likely comes from Pew...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/3...</td>\n",
       "      <td>36011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>doe boiling the same water twice make it dange...</td>\n",
       "      <td>11118</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/1...</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0</td>\n",
       "      <td>The claims\\n\\n\\nevery time the same water is b...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/1...</td>\n",
       "      <td>11119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question questionId  \\\n",
       "0                 can headbanging cause brain damage      14138   \n",
       "1  doe the shangrila diet work according to it su...      10103   \n",
       "2  can phobia be genetic but created in one gener...      18713   \n",
       "3  do of u american think that global warming is ...      36010   \n",
       "4  doe boiling the same water twice make it dange...      11118   \n",
       "\n",
       "                                         questionUrl         category  \\\n",
       "0  https://skeptics.stackexchange.com/questions/1...  medical-science   \n",
       "1  https://skeptics.stackexchange.com/questions/1...        nutrition   \n",
       "2  https://skeptics.stackexchange.com/questions/1...       psychology   \n",
       "3  https://skeptics.stackexchange.com/questions/3...   climate-change   \n",
       "4  https://skeptics.stackexchange.com/questions/1...        nutrition   \n",
       "\n",
       "   categoryId                                             answer  \\\n",
       "0           2  A number of injuries have been attributed to t...   \n",
       "1           0  The Shangri-La diet depends on two theories:\\n...   \n",
       "2           4  This question has remained unanswered yet not ...   \n",
       "3           1  The&nbsp;40% figure most likely comes from Pew...   \n",
       "4           0  The claims\\n\\n\\nevery time the same water is b...   \n",
       "\n",
       "                                           answerUrl answerId  \n",
       "0  https://skeptics.stackexchange.com/questions/1...    14139  \n",
       "1  https://skeptics.stackexchange.com/questions/1...    16121  \n",
       "2  https://skeptics.stackexchange.com/questions/1...    22322  \n",
       "3  https://skeptics.stackexchange.com/questions/3...    36011  \n",
       "4  https://skeptics.stackexchange.com/questions/1...    11119  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question'] = preprocess_text(df['question'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "        df, df['category'],stratify=df['category'], test_size=0.4)\n",
    "\n",
    "test_data, valid_data, test_labels, valid_labels = train_test_split(\n",
    "        test_data, test_labels, stratify=test_labels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>questionId</th>\n",
       "      <th>questionUrl</th>\n",
       "      <th>category</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>answer</th>\n",
       "      <th>answerUrl</th>\n",
       "      <th>answerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>do alcoholic digestive help digestion</td>\n",
       "      <td>7410</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/7410</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0</td>\n",
       "      <td>Maybe, maybe not...\\n\\nReference - Effect on g...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/7...</td>\n",
       "      <td>7420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>627</td>\n",
       "      <td>is sodium nitrite food additive e carcinogenic</td>\n",
       "      <td>28106</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2...</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0</td>\n",
       "      <td>There's good evidence for it.\\n\\n\"Red and proc...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2...</td>\n",
       "      <td>28416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>doe eating sugar feed yeast in the gut</td>\n",
       "      <td>18987</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/1...</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0</td>\n",
       "      <td>Auto-brewery syndrome is a well-known but rare...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/1...</td>\n",
       "      <td>18988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>can you deduce the quality of watermelon by ta...</td>\n",
       "      <td>20567</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2...</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0</td>\n",
       "      <td>There are a few papers assessing methods and r...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/2...</td>\n",
       "      <td>20586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1014</td>\n",
       "      <td>doe a lack of radiation shadow disprove the bi...</td>\n",
       "      <td>34226</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/3...</td>\n",
       "      <td>physics</td>\n",
       "      <td>3</td>\n",
       "      <td>The Big Bang was the whole universe. There was...</td>\n",
       "      <td>https://skeptics.stackexchange.com/questions/3...</td>\n",
       "      <td>34231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question questionId  \\\n",
       "120               do alcoholic digestive help digestion       7410   \n",
       "627      is sodium nitrite food additive e carcinogenic      28106   \n",
       "28               doe eating sugar feed yeast in the gut      18987   \n",
       "893   can you deduce the quality of watermelon by ta...      20567   \n",
       "1014  doe a lack of radiation shadow disprove the bi...      34226   \n",
       "\n",
       "                                            questionUrl   category  \\\n",
       "120   https://skeptics.stackexchange.com/questions/7410  nutrition   \n",
       "627   https://skeptics.stackexchange.com/questions/2...  nutrition   \n",
       "28    https://skeptics.stackexchange.com/questions/1...  nutrition   \n",
       "893   https://skeptics.stackexchange.com/questions/2...  nutrition   \n",
       "1014  https://skeptics.stackexchange.com/questions/3...    physics   \n",
       "\n",
       "      categoryId                                             answer  \\\n",
       "120            0  Maybe, maybe not...\\n\\nReference - Effect on g...   \n",
       "627            0  There's good evidence for it.\\n\\n\"Red and proc...   \n",
       "28             0  Auto-brewery syndrome is a well-known but rare...   \n",
       "893            0  There are a few papers assessing methods and r...   \n",
       "1014           3  The Big Bang was the whole universe. There was...   \n",
       "\n",
       "                                              answerUrl answerId  \n",
       "120   https://skeptics.stackexchange.com/questions/7...     7420  \n",
       "627   https://skeptics.stackexchange.com/questions/2...    28416  \n",
       "28    https://skeptics.stackexchange.com/questions/1...    18988  \n",
       "893   https://skeptics.stackexchange.com/questions/2...    20586  \n",
       "1014  https://skeptics.stackexchange.com/questions/3...    34231  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts of code provided in the tutorial was used. Reference: liar_liar_bilstm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1000\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "num_labels = len(label_map)\n",
    "batch_size = 64\n",
    "lr = 2e-4\n",
    "lstm_dim = 200\n",
    "n_epochs = 20\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub Word Byte Pair word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "\n",
    "bpemb_en = BPEmb(lang='en', dim=300, vs=25000)\n",
    "pretrained_embeddings = np.concatenate([bpemb_en.emb.vectors, np.zeros(shape=(1,300))], axis=0)\n",
    "vocabulary = bpemb_en.emb.index2word + ['[PAD]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDatasetReader():\n",
    "    \n",
    "    def __init__(self,df,tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        row = self.df.values[idx]\n",
    "        input_seq,seq_lens = text_to_batch_bilstm([row[0]], self.tokenizer) #sending a list of one row\n",
    "        label = label_map[row[3]]\n",
    "        return input_seq, seq_lens, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_batch_bilstm(text: List, tokenizer) -> Tuple[List, List]:\n",
    "    \n",
    "    \"\"\"tokenize and return tokenized ids and their lengths\"\"\"\n",
    "    input_ids = [tokenizer.encode_ids_with_eos(t) for t in text]\n",
    "    return input_ids, [len(ids) for ids in input_ids] #input_ids is list of lists [[token_ids_for_row1],[token_ids_row2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch_bilstm(input_data: Tuple) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    input_ids = [i[0][0] for i in input_data]\n",
    "    seq_lens = [i[1][0] for i in input_data]\n",
    "    labels = [i[2] for i in input_data]\n",
    "\n",
    "    max_length = max([len(i) for i in input_ids])\n",
    "\n",
    "    input_ids = [(i + [25000] * (max_length - len(i))) for i in input_ids]\n",
    "\n",
    "    assert (all(len(i) == max_length for i in input_ids))\n",
    "    return torch.tensor(input_ids), torch.tensor(seq_lens), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset readers and read data\n",
    "train_dataset = ClassificationDatasetReader(train_data, bpemb_en)\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch_bilstm)\n",
    "\n",
    "valid_dataset = ClassificationDatasetReader(valid_data, bpemb_en)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=len(valid_data), collate_fn=collate_batch_bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class LSTMNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_embeddings: torch.tensor, lstm_dim: int, dropout_prob: float = 0.1, n_classes: int = 5):\n",
    "        \n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        \n",
    "        #LSTM input\n",
    "        self.input_size = pretrained_embeddings.shape[1] #features in input\n",
    "        self.hidden_size = 200 \n",
    "        self.num_layers = 1 #default \n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1)\n",
    "        self.lstm = nn.LSTM(self.input_size,self.hidden_size,self.num_layers,batch_first=True,dropout=dropout_prob,bidirectional=True)\n",
    "        self.ff = nn.Linear(2*self.hidden_size,n_classes)\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "    def forward(self, inputs, input_lens, labels = None):\n",
    "        \n",
    "        # Get embeddings (b x sl x edim)\n",
    "        embeds = self.embeddings(inputs)\n",
    "        lstm_out, hidden = self.lstm(embeds)\n",
    "        \n",
    "        # Get the last output for classification (b x 2*lstm_dim)\n",
    "        ff_in = lstm_out.gather(1, input_lens.view(-1,1,1).expand(lstm_out.size(0), 1, lstm_out.size(2)) - 1).squeeze()\n",
    "        #print(input_lens.view(-1,1,1).expand(lstm_out.size(0), 1, lstm_out.size(2)))\n",
    "        \n",
    "        # Get logits (b x 2)\n",
    "        logits = self.ff(ff_in).view(-1, self.n_classes)\n",
    "        \n",
    "        outputs = (logits,)\n",
    "        if labels is not None:\n",
    "            # Xentropy loss\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = LSTMNetwork(\n",
    "    pretrained_embeddings=torch.FloatTensor(pretrained_embeddings), \n",
    "    lstm_dim=lstm_dim, \n",
    "    dropout_prob=0, \n",
    "    n_classes=len(label_map)\n",
    "  ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, labels):\n",
    "    return torch.sum(torch.argmax(logits, dim=-1) == labels).type(torch.float) / float(labels.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, valid_dl, optimizer, n_epochs, device):\n",
    "    \n",
    "    losses = []\n",
    "    best_acc = 0.0\n",
    "  \n",
    "    for ep in range(n_epochs):\n",
    "        loss_epoch = []\n",
    "        \n",
    "        for batch in tqdm(train_dl):\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids = batch[0]\n",
    "            seq_lens = batch[1]\n",
    "            labels = batch[2]\n",
    "\n",
    "            loss, logits = model(input_ids, seq_lens, labels=labels)\n",
    "            losses.append(loss.item())\n",
    "            loss_epoch.append(loss.item())\n",
    "      \n",
    "            #print(loss.dtype)\n",
    "            loss.backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "        #gc.collect()\n",
    "    \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_dl:\n",
    "\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids = batch[0]\n",
    "                seq_lens = batch[1]\n",
    "                labels = batch[2]\n",
    "\n",
    "                val_loss, logits = model(input_ids, seq_lens, labels=labels)\n",
    "                acc = accuracy(logits, labels)\n",
    "\n",
    "                print(f'Validation accuracy: {acc}, train loss: {sum(loss_epoch) / len(loss_epoch)}',\"val_loss: \",val_loss.item())\n",
    "                best_model = model.state_dict()\n",
    "\n",
    "                if acc > best_acc:\n",
    "                  #best_model = model.state_dict()\n",
    "                    best_acc = acc\n",
    "                #gc.collect()\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec81ba760b5e43ac9f18ccce0aebc327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(1.5469, device='cuda:0')\n",
      "Validation accuracy: 0.37383174896240234, train loss: 1.5766063809394837 val_loss:  1.5469024181365967\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de47e17dac114e9dbbb16d7899255639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(1.5009, device='cuda:0')\n",
      "Validation accuracy: 0.37383174896240234, train loss: 1.5296932816505433 val_loss:  1.5008717775344849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6341d7bdc94ca7b11a4d82b72460a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.3840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(1.4614, device='cuda:0')\n",
      "Validation accuracy: 0.37383174896240234, train loss: 1.4845430493354796 val_loss:  1.4614430665969849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5d8a8fe6d04e3d88db5263e4cd54e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(1.4142, device='cuda:0')\n",
      "Validation accuracy: 0.37383174896240234, train loss: 1.447383451461792 val_loss:  1.4142210483551025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163182e8357042cbbb2bf38ad4c04136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.3586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.3576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.5504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.4057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.3501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.3504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.3705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(1.3209, device='cuda:0')\n",
      "Validation accuracy: 0.37383174896240234, train loss: 1.3894691109657287 val_loss:  1.3208885192871094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b42fff32efd41cdaa0803e248773c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.3611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.1976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.2248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.3733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.2797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.2658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.0218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.3386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.3174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(1.1637, device='cuda:0')\n",
      "Validation accuracy: 0.485981285572052, train loss: 1.2761989831924438 val_loss:  1.1636801958084106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a0b8a063444e11ac25fef5adb6cc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.1857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.1032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.2591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.1852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.1139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.1240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.1631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.0119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(1.0350, device='cuda:0')\n",
      "Validation accuracy: 0.6214953064918518, train loss: 1.138337540626526 val_loss:  1.0349860191345215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b2358e3d7746d18df5e7688087c170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.0814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.1164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.0376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.0444, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.9267, device='cuda:0')\n",
      "Validation accuracy: 0.6822429895401001, train loss: 1.0217601180076599 val_loss:  0.9267167448997498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370c6c1690594e9da9ebf7cad531a380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(1.0033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.8514, device='cuda:0')\n",
      "Validation accuracy: 0.7149532437324524, train loss: 0.91543128490448 val_loss:  0.8513918519020081\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007140f044b242a38a9fbc704d58fcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9660, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.8056, device='cuda:0')\n",
      "Validation accuracy: 0.7196261286735535, train loss: 0.8334751963615418 val_loss:  0.8056080937385559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79422f98465447f7b76f831f4f570898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.7677, device='cuda:0')\n",
      "Validation accuracy: 0.7289719581604004, train loss: 0.7818633258342743 val_loss:  0.767652690410614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26b617cd5274a9cbf3c9487b64a797f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9024, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.8256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.7450, device='cuda:0')\n",
      "Validation accuracy: 0.7242990136146545, train loss: 0.7382800817489624 val_loss:  0.7450037598609924\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e71828777c403c9d73a82c7b038dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.7290, device='cuda:0')\n",
      "Validation accuracy: 0.7523364424705505, train loss: 0.6837431788444519 val_loss:  0.7290393710136414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e097dc45e54679a060bdc5e07ab3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.9279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.7229, device='cuda:0')\n",
      "Validation accuracy: 0.7336448431015015, train loss: 0.6427644610404968 val_loss:  0.7228673696517944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad89f581c4e454c9942ef05943bb8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.6961, device='cuda:0')\n",
      "Validation accuracy: 0.7523364424705505, train loss: 0.5950993746519089 val_loss:  0.6961320638656616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef893a36d98046a0ad6c1bf353c92ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.7157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.6814, device='cuda:0')\n",
      "Validation accuracy: 0.7710280418395996, train loss: 0.5510117322206497 val_loss:  0.6813513040542603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf19c25f199405c9eb24453b26de43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.6729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.6791, device='cuda:0')\n",
      "Validation accuracy: 0.7616822123527527, train loss: 0.5111506819725037 val_loss:  0.6790711879730225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15969e7186a14494b6aca0e339b06df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.3746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.6717, device='cuda:0')\n",
      "Validation accuracy: 0.7757009267807007, train loss: 0.4726714134216309 val_loss:  0.6716684103012085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b540db56014e4d0bb62bdba301fe5199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.3640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.5114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.3572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.3650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.6932, device='cuda:0')\n",
      "Validation accuracy: 0.7570093274116516, train loss: 0.43568646907806396 val_loss:  0.6931828260421753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a85f62a1d748d4875edc82f43fd68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.3970, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.3669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.3157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.3476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "tensor(0.4402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.float32\n",
      "\n",
      "tensor(0.6717, device='cuda:0')\n",
      "Validation accuracy: 0.7710280418395996, train loss: 0.4000479310750961 val_loss:  0.671684205532074\n"
     ]
    }
   ],
   "source": [
    "# Create the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Train\n",
    "model, losses = train(model, train_dl, valid_dl, optimizer, n_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
