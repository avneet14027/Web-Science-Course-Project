{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Question-Answer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>questionId</th>\n",
       "      <th>category</th>\n",
       "      <th>categoryId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Can headbanging cause brain damage?</td>\n",
       "      <td>14138</td>\n",
       "      <td>medical-science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Does the Shangri-La diet work (according to it...</td>\n",
       "      <td>10103</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Can phobias be genetic, but created in one gen...</td>\n",
       "      <td>18713</td>\n",
       "      <td>psychology</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Do 40% of U.S. Americans think that global war...</td>\n",
       "      <td>36010</td>\n",
       "      <td>climate-change</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Does boiling the same water twice make it dang...</td>\n",
       "      <td>11118</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question questionId  \\\n",
       "0                Can headbanging cause brain damage?      14138   \n",
       "1  Does the Shangri-La diet work (according to it...      10103   \n",
       "2  Can phobias be genetic, but created in one gen...      18713   \n",
       "3  Do 40% of U.S. Americans think that global war...      36010   \n",
       "4  Does boiling the same water twice make it dang...      11118   \n",
       "\n",
       "          category  categoryId  \n",
       "0  medical-science           2  \n",
       "1        nutrition           0  \n",
       "2       psychology           4  \n",
       "3   climate-change           1  \n",
       "4        nutrition           0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"D:\\\\WebScience\\\\web_science_dataset.jsonl\"\n",
    "json_data = []\n",
    "json_data_list = []\n",
    "\n",
    "\n",
    "with open(filename) as f:\n",
    "    json_data = f.readlines()\n",
    "    \n",
    "for item in json_data:\n",
    "    json_data_list.append(json.loads(item))\n",
    "    \n",
    "df = pd.DataFrame(json_data_list)\n",
    "df.head()\n",
    "\n",
    "question_df = pd.DataFrame(df[['question','questionId','category','categoryId']])\n",
    "question_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"recommender_train.tsv\"\n",
    "test_file = \"recommender_test.tsv\"\n",
    "train = pd.read_csv(train_file,delimiter=\"\\t\")\n",
    "test =  pd.read_csv(test_file,delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>questionID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5205</td>\n",
       "      <td>17488</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5205</td>\n",
       "      <td>8080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5205</td>\n",
       "      <td>36393</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5205</td>\n",
       "      <td>44399</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5205</td>\n",
       "      <td>44167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2339</td>\n",
       "      <td>5432</td>\n",
       "      <td>8054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>5432</td>\n",
       "      <td>17594</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2341</td>\n",
       "      <td>5432</td>\n",
       "      <td>22562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2342</td>\n",
       "      <td>5432</td>\n",
       "      <td>22250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2343</td>\n",
       "      <td>5432</td>\n",
       "      <td>1238</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2344 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  questionID  rating\n",
       "0       5205       17488       2\n",
       "1       5205        8080       2\n",
       "2       5205       36393       2\n",
       "3       5205       44399       2\n",
       "4       5205       44167       2\n",
       "...      ...         ...     ...\n",
       "2339    5432        8054       1\n",
       "2340    5432       17594       2\n",
       "2341    5432       22562       2\n",
       "2342    5432       22250       2\n",
       "2343    5432        1238       2\n",
       "\n",
       "[2344 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID         int64\n",
       "questionID     int64\n",
       "recommend     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()\n",
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Users DF dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df = question_df.astype({'questionId': 'int64'})\n",
    "category_map = dict(zip(question_df['category'],question_df['categoryId']))\n",
    "ques_cat_map = dict(zip(question_df['questionId'],question_df['categoryId']))\n",
    "questext_id_map = dict(zip(question_df['questionId'],question_df['question']))\n",
    "\n",
    "# loading data \n",
    "folder_path = \"C:\\\\Users\\\\Reen\\\\Desktop\\\\web science\\\\crowdsourced_data\\\\submissions_fixed_anonymized\"\n",
    "\n",
    "user_df_dict = {}\n",
    "\n",
    "for root,dirs,files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        filename = folder_path+\"\\\\\"+file\n",
    "        df = pd.read_csv(filename)\n",
    "        df = df.drop(['Question','Answer URL','Answer Label','Answer Quality','Factual'],axis=1)\n",
    "        \n",
    "        #add category id column\n",
    "        df['categoryId'] = df['questionId'].map(ques_cat_map)\n",
    "        #df = df.dropna(axis=0)\n",
    "    \n",
    "        #add category column\n",
    "        category_map_rev = {v:k for k,v in category_map.items()}\n",
    "        df['category'] = df['categoryId'].map(category_map_rev)\n",
    "        \n",
    "        #add clean question column\n",
    "        df['question'] = df['questionId'].map(questext_id_map)\n",
    "        \n",
    "        key = file.replace('.csv','')\n",
    "        key = int(key.replace('WS',''))\n",
    "        \n",
    "        user_df_dict[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return (' '.join(lemmatizer.lemmatize(w) for w in word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):    \n",
    "    \n",
    "    # convert to lowercase\n",
    "    df = df.str.lower()\n",
    "    \n",
    "    # remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    df = df.str.translate(translator)\n",
    "    \n",
    "    # remove digits\n",
    "    translator = str.maketrans('', '', string.digits) \n",
    "    df = df.str.translate(translator)\n",
    "    \n",
    "    # remove leading/trailing whitespaces\n",
    "    df = df.str.strip()\n",
    "    \n",
    "    #lemmatize\n",
    "    df = df.apply(lemmatize_text)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessed column to main dataframe\n",
    "def get_preprocessed_df(df,qid_rowid_map):\n",
    "    \n",
    "    preprocessed_data = preprocess_text(df['question'])\n",
    "    preprocessed_data = preprocessed_data.rename('preprocessed question')\n",
    "    \n",
    "    resulting_df = pd.concat([df,preprocessed_data],axis=1)    \n",
    "    \n",
    "    resulting_df['row QID'] = resulting_df['questionId'].map(qid_rowid_map)\n",
    "    #resulting_df.head()\n",
    "    \n",
    "    return resulting_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data for recommender systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns subset of dataframe of a particular category\n",
    "def get_category_question_df(category_id,df):\n",
    "    \n",
    "    ques_category_df = df[df['categoryId']==category_id]\n",
    "    return ques_category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns subset of dataframe of a particular category\n",
    "def get_categories_question_df(category_ids,df):\n",
    "    \n",
    "    ques_category_df = df.loc[df['categoryId'].isin(category_ids)]\n",
    "    return ques_category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>questionId</th>\n",
       "      <th>category</th>\n",
       "      <th>categoryId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Can headbanging cause brain damage?</td>\n",
       "      <td>14138</td>\n",
       "      <td>medical-science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Can phobias be genetic, but created in one gen...</td>\n",
       "      <td>18713</td>\n",
       "      <td>psychology</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Do 40% of U.S. Americans think that global war...</td>\n",
       "      <td>36010</td>\n",
       "      <td>climate-change</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Can airport X-ray machines scramble Kindle scr...</td>\n",
       "      <td>8580</td>\n",
       "      <td>physics</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Is the ninth wave the largest?</td>\n",
       "      <td>9805</td>\n",
       "      <td>physics</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>Does Blue monday exist?</td>\n",
       "      <td>19223</td>\n",
       "      <td>psychology</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1061</td>\n",
       "      <td>Do the recent CLOUD results have significant i...</td>\n",
       "      <td>5983</td>\n",
       "      <td>climate-change</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1063</td>\n",
       "      <td>Does the G-Spot exist?</td>\n",
       "      <td>936</td>\n",
       "      <td>medical-science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1064</td>\n",
       "      <td>Are sea salt soaks beneficial for healing a bo...</td>\n",
       "      <td>7755</td>\n",
       "      <td>medical-science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1065</td>\n",
       "      <td>Are there any viable shortcuts to stop smoking?</td>\n",
       "      <td>514</td>\n",
       "      <td>medical-science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  questionId  \\\n",
       "0                   Can headbanging cause brain damage?       14138   \n",
       "2     Can phobias be genetic, but created in one gen...       18713   \n",
       "3     Do 40% of U.S. Americans think that global war...       36010   \n",
       "7     Can airport X-ray machines scramble Kindle scr...        8580   \n",
       "8                        Is the ninth wave the largest?        9805   \n",
       "...                                                 ...         ...   \n",
       "1060                            Does Blue monday exist?       19223   \n",
       "1061  Do the recent CLOUD results have significant i...        5983   \n",
       "1063                             Does the G-Spot exist?         936   \n",
       "1064  Are sea salt soaks beneficial for healing a bo...        7755   \n",
       "1065    Are there any viable shortcuts to stop smoking?         514   \n",
       "\n",
       "             category  categoryId  \n",
       "0     medical-science           2  \n",
       "2          psychology           4  \n",
       "3      climate-change           1  \n",
       "7             physics           3  \n",
       "8             physics           3  \n",
       "...               ...         ...  \n",
       "1060       psychology           4  \n",
       "1061   climate-change           1  \n",
       "1063  medical-science           2  \n",
       "1064  medical-science           2  \n",
       "1065  medical-science           2  \n",
       "\n",
       "[670 rows x 4 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_categories_question_df([1,2,3,4],question_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_vocab_tfidf(k,df):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\") #max_features=k\n",
    "    response = vectorizer.fit_transform(df['preprocessed question'])\n",
    "    response = response.todense()\n",
    "    #response.shape\n",
    "    \n",
    "    features = np.array(vectorizer.get_feature_names())\n",
    "    sorted_ = np.argsort(response).flatten()[::-1]\n",
    "    \n",
    "    sorted_indices = np.asarray((sorted_[0,:k]))[0]\n",
    "        \n",
    "    top_k_tfidf_matrix = np.array([top_k_tfidf_row_vector(response,row_idx,sorted_indices) for row_idx in range(len(df))])\n",
    "   \n",
    "    return top_k_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_tfidf_row_vector(tfidf_matrix,row_idx,top_k_indices):\n",
    "    row_vec = np.asarray(tfidf_matrix[row_idx])[0]\n",
    "    #modified_row_vec = [row_vec[i] if i in top_k_indices else 0 for i in range(len(row_vec))]\n",
    "    #return modified_row_vec\n",
    "    return row_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Profile Vector Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_user_profile_vectors(category_ids,train_liked,user_df_dict,top_k_tfidf_matrix,qid_rowid_map):\n",
    "    \n",
    "    \"\"\"\n",
    "    category_ids: list\n",
    "    train_liked: df containing only liked items\n",
    "    user_df_dict: dictionary of all user dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    user_profile_vectors = []\n",
    "    users = []\n",
    "    \n",
    "    for user in user_df_dict.keys():\n",
    "        \n",
    "        liked_qids = set((train_liked.loc[(train_liked['userID']==user)])['questionID'])\n",
    "        \n",
    "        user_df = user_df_dict[user]\n",
    "        \n",
    "        cat_liked_df = user_df.loc[(user_df['categoryId'].isin(category_ids)) & (user_df['questionId'].isin(liked_qids))]\n",
    "        \n",
    "\n",
    "        if(len(cat_liked_df)!=0):\n",
    "            \n",
    "            qids = list(set(cat_liked_df['questionId']))\n",
    "            row_ids = [qid_rowid_map[qid] for qid in qids]\n",
    "            \n",
    "            user_profile_vector = np.average(top_k_tfidf_matrix[row_ids,:],axis=0)\n",
    "            \n",
    "            user_profile_vectors.append(user_profile_vector)\n",
    "            users.append(user)\n",
    "    \n",
    "    \n",
    "    userid_row_map = dict(zip(users,list(range(0,len(users)))))\n",
    "    profile_vector_mat = np.array(user_profile_vectors)\n",
    "    \n",
    "    return userid_row_map,profile_vector_mat\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_sim(profile_vectors):\n",
    "    return cosine_similarity(profile_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User specific liked/not liked items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_specific_user_rated_items(category_ids,df,user_df_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    df: either the df with recommend = yes or recommend = no\n",
    "    \"\"\"\n",
    "    \n",
    "    user_rated_dict = {}\n",
    "    \n",
    "    for user in user_df_dict.keys():\n",
    "        \n",
    "        #get user rated qids from liked df\n",
    "        qids = set((df.loc[(df['userID']==user)])['questionID'])\n",
    "        user_df = user_df_dict[user]\n",
    "        \n",
    "        #filter quids according to category\n",
    "        cat_df = user_df.loc[(user_df['categoryId'].isin(category_ids)) & (user_df['questionId'].isin(qids))]\n",
    "        \n",
    "        if(len(cat_df)!=0):\n",
    "            user_rated_dict[user] = list(set(cat_df['questionId']))\n",
    "    \n",
    "    return user_rated_dict\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_similar_users(k,cosine_matrix,userid_row_map):\n",
    "    \n",
    "    \"\"\" top_k_similar_users = {userid:{similar_users}}, similar_users={friend_id:similarity_score}\n",
    "    \"\"\"\n",
    "    \n",
    "    top_k_friends = {}\n",
    "    user_map = {v: k for k, v in userid_row_map.items()}\n",
    "    \n",
    "    for userid in userid_row_map.keys():\n",
    "        \n",
    "        row_id = userid_row_map[userid]\n",
    "        \n",
    "        user_vec = cosine_matrix[row_id]\n",
    "            \n",
    "        sorted_indices = (np.argsort(user_vec)[::-1][:k+1])[1:]\n",
    "        top_k_friends_scores = [user_vec[i] for i in sorted_indices]\n",
    "\n",
    "        \n",
    "        top_k_friends_ids = [user_map[i] for i in sorted_indices]\n",
    "\n",
    "        top_k_friends[userid] = top_k_friends_ids\n",
    "\n",
    "    return top_k_friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_specific_user_recommendations(top_k_friends,train_user_liked_items):\n",
    "    \n",
    "    \"\"\"return {userid: recommendations_from_top_k} where recommendations_from_top_k is {friendid:recommended question ids}\n",
    "    \"\"\"\n",
    "        \n",
    "    userids = top_k_friends.keys()\n",
    "    \n",
    "    top_k_friend_recommendations = {}\n",
    "    \n",
    "    for userid in userids:\n",
    "        \n",
    "        # top k friends\n",
    "        top_k_friends_current = top_k_friends[userid]\n",
    "        \n",
    "        recommended = {}\n",
    "        \n",
    "        # find items liked by each friend\n",
    "        for friend in top_k_friends_current:\n",
    "            \n",
    "            if(friend in train_user_liked_items.keys()):\n",
    "        \n",
    "                recommended[friend] = train_user_liked_items[friend]\n",
    "            \n",
    "                top_k_friend_recommendations[userid] = recommended \n",
    "    \n",
    "    return top_k_friend_recommendations \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(top_k_friend_recommendations,true_liked_items,true_not_liked_items):\n",
    "    \n",
    "    test_userids = true_liked_items.keys()\n",
    "    acc = 0\n",
    "    \n",
    "    total_acc_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    final_prec = final_recall = final_f1 = 0\n",
    "    \n",
    "    for userid in test_userids:\n",
    "        \n",
    "        true_items_l = true_liked_items[userid]\n",
    "        \n",
    "        true_items_nl = []\n",
    "        if(userid) in true_not_liked_items.keys():\n",
    "            true_items_nl = true_not_liked_items[userid]\n",
    "        \n",
    "        true_positives = 0\n",
    "        true_negatives = 0\n",
    "        false_positives = 0\n",
    "        false_negatives = 0\n",
    "        \n",
    "        if(userid in top_k_friend_recommendations.keys()):\n",
    "            \n",
    "            \n",
    "            recommended_items = top_k_friend_recommendations[userid].values()\n",
    "            recommendations = [item for sublist in recommended_items for item in sublist]\n",
    "            \n",
    "            true_positives = float(len(set(recommendations).intersection(set(true_items_l))))\n",
    "            false_negatives = len(true_items_l) - true_positives\n",
    "            \n",
    "            if(true_items_nl):\n",
    "                false_positives = float(len(set(recommendations).intersection(set(true_items_nl))))\n",
    "                true_negatives = len(true_items_nl) - false_positives\n",
    "                \n",
    "                \n",
    "    \n",
    "        user_acc = float((true_positives)+true_negatives) / float(len(true_items_l)+len(true_items_nl))\n",
    "        total_acc_list.append(user_acc)\n",
    "        \n",
    "        \n",
    "        user_prec = user_recall = 0\n",
    "        \n",
    "        if((true_positives)!=0 or (false_positives)!=0):\n",
    "            user_prec = float(true_positives / (true_positives + false_positives))\n",
    "            precision_list.append(user_prec)\n",
    "        \n",
    "        if((true_positives)!=0 or (true_positives)!=0):\n",
    "            user_recall = float(true_positives / (true_positives + false_negatives))\n",
    "            recall_list.append(user_recall)\n",
    "        \n",
    "        if(user_prec!=0 or user_recall!=0):\n",
    "            user_f1 = (2 * user_prec * user_recall) / (user_prec + user_recall)\n",
    "            f1_list.append(user_f1)\n",
    "\n",
    "    final_acc = float(sum(total_acc_list)/len(total_acc_list))\n",
    "    \n",
    "    if(precision_list):\n",
    "        final_prec = float(sum(precision_list)/len(precision_list))\n",
    "    if(recall_list):\n",
    "        final_recall = float(sum(recall_list)/len(recall_list))\n",
    "    if(f1_list):\n",
    "        final_f1 = float(sum(f1_list)/len(f1_list))\n",
    "    \n",
    "    return (final_acc,final_prec,final_recall,final_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining some globals\n",
    "\n",
    "train_liked = train.loc[train['rating']!=1]\n",
    "test_liked = test.loc[test['recommend']==\"Yes\"]\n",
    "test_not_liked = test.loc[test['recommend']==\"No\"]\n",
    "\n",
    "k_friends=10\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    accuracy_all = []\n",
    "    precision_all = []\n",
    "    recall_all = []\n",
    "    f1_all = []\n",
    "    \n",
    "    for i in range(5):\n",
    "\n",
    "        \"\"\"Train\"\"\"\n",
    "        train_category_id = [j for j in range(0,5) if j!=i]\n",
    "        #train_category_id = i\n",
    "        #print(train_category_id)\n",
    "\n",
    "        #get category specific df\n",
    "        cat_ques_df = get_categories_question_df(train_category_id,question_df)\n",
    "        qid_rowid_map = {v:k for k,v in enumerate(cat_ques_df['questionId'])} #question_id_unique? maybe\n",
    "        \n",
    "        #preprocess df\n",
    "        result_df = get_preprocessed_df(cat_ques_df,qid_rowid_map)\n",
    "\n",
    "        #tfidf matrix for all questions in a particular category\n",
    "        top_k_tfidf_matrix = get_topk_vocab_tfidf(k,result_df)\n",
    "\n",
    "        #get user profile vectors\n",
    "        userid_row_map,profile_vector_mat = compute_user_profile_vectors(train_category_id,train_liked,user_df_dict,top_k_tfidf_matrix,qid_rowid_map)\n",
    "        \n",
    "        #calculate similarity \n",
    "        similarity_matrix = compute_cosine_sim(profile_vector_mat)\n",
    "\n",
    "        #get top k friends\n",
    "        top_k_friends = top_k_similar_users(k_friends,similarity_matrix,userid_row_map)\n",
    "  \n",
    "\n",
    "        \"\"\"Test \"\"\"\n",
    "\n",
    "        test_category_id = i\n",
    "\n",
    "        #get category specific items liked by users in the training set\n",
    "        train_user_liked_items = get_category_specific_user_rated_items([test_category_id],train_liked,user_df_dict)\n",
    "\n",
    "        #get top k friends recommendations based on test category\n",
    "        recommendations = get_category_specific_user_recommendations(top_k_friends,train_user_liked_items)\n",
    "\n",
    "        #liked items of those unique users {userid: liked_item}\n",
    "        test_user_liked_items = get_category_specific_user_rated_items([test_category_id],test_liked,user_df_dict)\n",
    "\n",
    "        #not liked items of those unique users {userid: not_liked}\n",
    "        test_not_liked_items = get_category_specific_user_rated_items([test_category_id],test_not_liked,user_df_dict)\n",
    "\n",
    "\n",
    "        #get recommendations of top k friends for each user in unique users in test set and compute accuracy\n",
    "        (accuracy,precision,recall,f1) = compute_accuracy(recommendations,test_user_liked_items,test_not_liked_items)\n",
    "            \n",
    "        accuracy_all.append(accuracy)\n",
    "        precision_all.append(precision)\n",
    "        recall_all.append(recall)\n",
    "        f1_all.append(f1)          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5046895491339937,\n",
       " 0.5769230769230769,\n",
       " 0.5322751322751323,\n",
       " 0.5231150793650793,\n",
       " 0.49723809523809526]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4513333333333333,\n",
       " 0.7083333333333334,\n",
       " 0.6140350877192983,\n",
       " 0.5746376811594203,\n",
       " 0.7913333333333334]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6041950113378685,\n",
       " 0.6962962962962963,\n",
       " 0.7488888888888889,\n",
       " 0.693859649122807,\n",
       " 0.5426666666666666]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5761904761904763,\n",
       " 0.4166666666666667,\n",
       " 0.6799999999999999,\n",
       " 0.5619047619047618,\n",
       " 0.5742424242424243]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
