{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Question-Answer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>questionId</th>\n",
       "      <th>category</th>\n",
       "      <th>categoryId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Can headbanging cause brain damage?</td>\n",
       "      <td>14138</td>\n",
       "      <td>medical-science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Does the Shangri-La diet work (according to it...</td>\n",
       "      <td>10103</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Can phobias be genetic, but created in one gen...</td>\n",
       "      <td>18713</td>\n",
       "      <td>psychology</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Do 40% of U.S. Americans think that global war...</td>\n",
       "      <td>36010</td>\n",
       "      <td>climate-change</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Does boiling the same water twice make it dang...</td>\n",
       "      <td>11118</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question questionId  \\\n",
       "0                Can headbanging cause brain damage?      14138   \n",
       "1  Does the Shangri-La diet work (according to it...      10103   \n",
       "2  Can phobias be genetic, but created in one gen...      18713   \n",
       "3  Do 40% of U.S. Americans think that global war...      36010   \n",
       "4  Does boiling the same water twice make it dang...      11118   \n",
       "\n",
       "          category  categoryId  \n",
       "0  medical-science           2  \n",
       "1        nutrition           0  \n",
       "2       psychology           4  \n",
       "3   climate-change           1  \n",
       "4        nutrition           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"D:\\\\WebScience\\\\web_science_dataset.jsonl\"\n",
    "json_data = []\n",
    "json_data_list = []\n",
    "\n",
    "\n",
    "with open(filename) as f:\n",
    "    json_data = f.readlines()\n",
    "    \n",
    "for item in json_data:\n",
    "    json_data_list.append(json.loads(item))\n",
    "    \n",
    "df = pd.DataFrame(json_data_list)\n",
    "df.head()\n",
    "\n",
    "question_df = pd.DataFrame(df[['question','questionId','category','categoryId']])\n",
    "question_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"recommender_train.tsv\"\n",
    "test_file = \"recommender_test.tsv\"\n",
    "train = pd.read_csv(train_file,delimiter=\"\\t\")\n",
    "test =  pd.read_csv(test_file,delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>questionID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5205</td>\n",
       "      <td>17488</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5205</td>\n",
       "      <td>8080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5205</td>\n",
       "      <td>36393</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5205</td>\n",
       "      <td>44399</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5205</td>\n",
       "      <td>44167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2339</td>\n",
       "      <td>5432</td>\n",
       "      <td>8054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>5432</td>\n",
       "      <td>17594</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2341</td>\n",
       "      <td>5432</td>\n",
       "      <td>22562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2342</td>\n",
       "      <td>5432</td>\n",
       "      <td>22250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2343</td>\n",
       "      <td>5432</td>\n",
       "      <td>1238</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2344 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID  questionID  rating\n",
       "0       5205       17488       2\n",
       "1       5205        8080       2\n",
       "2       5205       36393       2\n",
       "3       5205       44399       2\n",
       "4       5205       44167       2\n",
       "...      ...         ...     ...\n",
       "2339    5432        8054       1\n",
       "2340    5432       17594       2\n",
       "2341    5432       22562       2\n",
       "2342    5432       22250       2\n",
       "2343    5432        1238       2\n",
       "\n",
       "[2344 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID         int64\n",
       "questionID     int64\n",
       "recommend     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()\n",
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Users DF dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df = question_df.astype({'questionId': 'int64'})\n",
    "category_map = dict(zip(question_df['category'],question_df['categoryId']))\n",
    "ques_cat_map = dict(zip(question_df['questionId'],question_df['categoryId']))\n",
    "questext_id_map = dict(zip(question_df['questionId'],question_df['question']))\n",
    "\n",
    "# loading data \n",
    "folder_path = \"C:\\\\Users\\\\Reen\\\\Desktop\\\\web science\\\\crowdsourced_data\\\\submissions_fixed_anonymized\"\n",
    "\n",
    "user_df_dict = {}\n",
    "\n",
    "for root,dirs,files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        filename = folder_path+\"\\\\\"+file\n",
    "        df = pd.read_csv(filename)\n",
    "        df = df.drop(['Question','Answer URL','Answer Label','Answer Quality','Factual'],axis=1)\n",
    "        \n",
    "        #add category id column\n",
    "        df['categoryId'] = df['questionId'].map(ques_cat_map)\n",
    "        #df = df.dropna(axis=0)\n",
    "    \n",
    "        #add category column\n",
    "        category_map_rev = {v:k for k,v in category_map.items()}\n",
    "        df['category'] = df['categoryId'].map(category_map_rev)\n",
    "        \n",
    "        #add clean question column\n",
    "        df['question'] = df['questionId'].map(questext_id_map)\n",
    "        \n",
    "        key = file.replace('.csv','')\n",
    "        key = int(key.replace('WS',''))\n",
    "        \n",
    "        user_df_dict[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return (' '.join(lemmatizer.lemmatize(w) for w in word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):    \n",
    "    \n",
    "    # convert to lowercase\n",
    "    df = df.str.lower()\n",
    "    \n",
    "    # remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    df = df.str.translate(translator)\n",
    "    \n",
    "    # remove digits\n",
    "    translator = str.maketrans('', '', string.digits) \n",
    "    df = df.str.translate(translator)\n",
    "    \n",
    "    # remove leading/trailing whitespaces\n",
    "    df = df.str.strip()\n",
    "    \n",
    "    #lemmatize\n",
    "    df = df.apply(lemmatize_text)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessed column to main dataframe\n",
    "def get_preprocessed_df(df,qid_rowid_map):\n",
    "    \n",
    "    preprocessed_data = preprocess_text(df['question'])\n",
    "    preprocessed_data = preprocessed_data.rename('preprocessed question')\n",
    "    \n",
    "    resulting_df = pd.concat([df,preprocessed_data],axis=1)    \n",
    "    \n",
    "    resulting_df['row QID'] = resulting_df['questionId'].map(qid_rowid_map)\n",
    "    #resulting_df.head()\n",
    "    \n",
    "    return resulting_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data for recommender systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns subset of dataframe of a particular category\n",
    "def get_category_question_df(category_id,df):\n",
    "    \n",
    "    ques_category_df = df[df['categoryId']==category_id]\n",
    "    return ques_category_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import tokenize\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = \"C:\\\\Users\\\\Reen\\\\Desktop\\\\web science\\\\WordEmbeddings\\\\GoogleNews-vectors-negative300.bin.gz\"\n",
    "word_to_vec_model = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True,limit=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vector(word2vec_model, words):\n",
    "    \n",
    "    # remove out-of-vocabulary words\n",
    "    words_ = [word for word in words if word in word2vec_model.vocab]\n",
    "    if len(words_) >= 1:\n",
    "        return np.mean(word2vec_model[words_], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_matrix(k,df):\n",
    "    vectors = []\n",
    "    for item in question_df['question'].values:\n",
    "        item = (remove_stopwords(item))\n",
    "        vector = (get_mean_vector(word_to_vec_model, item.split(\" \")))\n",
    "        if(vector is not None):\n",
    "            vectors.append(vector)\n",
    "        else:\n",
    "            vectors.append(np.zeros(300))\n",
    "    \n",
    "    vectors_ = np.array(vectors)\n",
    "    return vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_vocab_tfidf(k,df):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\") #max_features=k\n",
    "    response = vectorizer.fit_transform(df['preprocessed question'])\n",
    "    response = response.todense()\n",
    "    #response.shape\n",
    "    \n",
    "    features = np.array(vectorizer.get_feature_names())\n",
    "    sorted_ = np.argsort(response).flatten()[::-1]\n",
    "    \n",
    "    sorted_indices = np.asarray((sorted_[0,:k]))[0]\n",
    "        \n",
    "    top_k_tfidf_matrix = np.array([top_k_tfidf_row_vector(response,row_idx,sorted_indices) for row_idx in range(len(df))])\n",
    "   \n",
    "    return top_k_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_tfidf_row_vector(tfidf_matrix,row_idx,top_k_indices):\n",
    "    row_vec = np.asarray(tfidf_matrix[row_idx])[0]\n",
    "    #modified_row_vec = [row_vec[i] if i in top_k_indices else 0 for i in range(len(row_vec))]\n",
    "    #return modified_row_vec\n",
    "    return row_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Profile Vector Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_user_profile_vectors(category_ids,train_liked,user_df_dict,top_k_tfidf_matrix,qid_rowid_map):\n",
    "    \n",
    "    \"\"\"\n",
    "    category_ids: list\n",
    "    train_liked: df containing only liked items\n",
    "    user_df_dict: dictionary of all user dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    user_profile_vectors = []\n",
    "    users = []\n",
    "    \n",
    "    for user in user_df_dict.keys():\n",
    "        \n",
    "        liked_qids = set((train_liked.loc[(train_liked['userID']==user)])['questionID'])\n",
    "        user_df = user_df_dict[user]\n",
    "        \n",
    "        cat_liked_df = user_df.loc[(user_df['categoryId'].isin(category_ids)) & (user_df['questionId'].isin(liked_qids))]\n",
    "        \n",
    "        if(len(cat_liked_df)!=0):\n",
    "            \n",
    "            #print(len(cat_liked_df))\n",
    "            \n",
    "            qids = list(set(cat_liked_df['questionId']))\n",
    "            row_ids = [qid_rowid_map[qid] for qid in qids]\n",
    "            \n",
    "            user_profile_vector = np.average(top_k_tfidf_matrix[row_ids,:],axis=0)\n",
    "            #print(user_profile_vector.shape)\n",
    "            \n",
    "            user_profile_vectors.append(user_profile_vector)\n",
    "            users.append(user)\n",
    "    \n",
    "    \n",
    "    userid_row_map = dict(zip(users,list(range(0,len(users)))))\n",
    "    profile_vector_mat = np.array(user_profile_vectors)\n",
    "    \n",
    "    return userid_row_map,profile_vector_mat\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_sim(profile_vectors):\n",
    "    return cosine_similarity(profile_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User specific liked/not liked items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_specific_user_rated_items(category_ids,df,user_df_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    df: either the df with recommend = yes or recommend = no\n",
    "    \"\"\"\n",
    "    \n",
    "    user_rated_dict = {}\n",
    "    \n",
    "    for user in user_df_dict.keys():\n",
    "        \n",
    "        #get user rated qids from liked df\n",
    "        qids = set((df.loc[(df['userID']==user)])['questionID'])\n",
    "        user_df = user_df_dict[user]\n",
    "        \n",
    "        #filter quids according to category\n",
    "        cat_df = user_df.loc[(user_df['categoryId'].isin(category_ids)) & (user_df['questionId'].isin(qids))]\n",
    "        #print(cat_df.head())\n",
    "        \n",
    "        if(len(cat_df)!=0):\n",
    "            user_rated_dict[user] = list(set(cat_df['questionId']))\n",
    "    \n",
    "    return user_rated_dict\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_similar_users(k,cosine_matrix,userid_row_map):\n",
    "    \n",
    "    \"\"\" top_k_similar_users = {userid:{similar_users}}, similar_users={friend_id:similarity_score}\n",
    "    \"\"\"\n",
    "    \n",
    "    top_k_friends = {}\n",
    "    user_map = {v: k for k, v in userid_row_map.items()}\n",
    "    \n",
    "    for userid in userid_row_map.keys():\n",
    "        \n",
    "        row_id = userid_row_map[userid]\n",
    "        \n",
    "        user_vec = cosine_matrix[row_id]\n",
    "            \n",
    "        sorted_indices = (np.argsort(user_vec)[::-1][:k+1])[1:]\n",
    "        top_k_friends_scores = [user_vec[i] for i in sorted_indices]\n",
    "\n",
    "        \n",
    "        top_k_friends_ids = [user_map[i] for i in sorted_indices]\n",
    "\n",
    "        top_k_friends[userid] = top_k_friends_ids\n",
    "\n",
    "    return top_k_friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_specific_user_recommendations(top_k_friends,train_user_liked_items):\n",
    "    \n",
    "    \"\"\"return {userid: recommendations_from_top_k} where recommendations_from_top_k is {friendid:recommended question ids}\n",
    "    \"\"\"\n",
    "        \n",
    "    userids = top_k_friends.keys()\n",
    "    \n",
    "    top_k_friend_recommendations = {}\n",
    "    \n",
    "    for userid in userids:\n",
    "        \n",
    "        # top k friends\n",
    "        top_k_friends_current = top_k_friends[userid]\n",
    "        \n",
    "        recommended = {}\n",
    "        \n",
    "        # find items liked by each friend\n",
    "        for friend in top_k_friends_current:\n",
    "        \n",
    "            if(friend in train_user_liked_items.keys()):\n",
    "                recommended[friend] = train_user_liked_items[friend]\n",
    "                \n",
    "        if(len(recommended)):  \n",
    "            top_k_friend_recommendations[userid] = recommended \n",
    "    \n",
    "    return top_k_friend_recommendations \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(top_k_friend_recommendations,true_liked_items,true_not_liked_items):\n",
    "    \n",
    "    test_userids = true_liked_items.keys()\n",
    "    acc = 0\n",
    "    \n",
    "    total_acc_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    final_prec = final_recall = final_f1 = 0\n",
    "    \n",
    "    for userid in test_userids:\n",
    "        \n",
    "        true_items_l = true_liked_items[userid]\n",
    "        \n",
    "        true_items_nl = []\n",
    "        if(userid) in true_not_liked_items.keys():\n",
    "            true_items_nl = true_not_liked_items[userid]\n",
    "        \n",
    "        true_positives = 0\n",
    "        true_negatives = 0\n",
    "        false_positives = 0\n",
    "        false_negatives = 0\n",
    "        \n",
    "        if(userid in top_k_friend_recommendations.keys()):\n",
    "            \n",
    "            \n",
    "            recommended_items = top_k_friend_recommendations[userid].values()\n",
    "            recommendations = [item for sublist in recommended_items for item in sublist]\n",
    "            \n",
    "            true_positives = float(len(set(recommendations).intersection(set(true_items_l))))\n",
    "            false_negatives = len(true_items_l) - true_positives\n",
    "            \n",
    "            if(true_items_nl):\n",
    "                false_positives = float(len(set(recommendations).intersection(set(true_items_nl))))\n",
    "                true_negatives = len(true_items_nl) - false_positives\n",
    "                \n",
    "                \n",
    "    \n",
    "        user_acc = float((true_positives)+true_negatives) / float(len(true_items_l)+len(true_items_nl))\n",
    "        total_acc_list.append(user_acc)\n",
    "        \n",
    "        \n",
    "        user_prec = user_recall = 0\n",
    "        \n",
    "        if((true_positives)!=0 or (false_positives)!=0):\n",
    "            user_prec = float(true_positives / (true_positives + false_positives))\n",
    "            precision_list.append(user_prec)\n",
    "        \n",
    "        if((true_positives)!=0 or (true_positives)!=0):\n",
    "            user_recall = float(true_positives / (true_positives + false_negatives))\n",
    "            recall_list.append(user_recall)\n",
    "        \n",
    "        if(user_prec!=0 or user_recall!=0):\n",
    "            user_f1 = (2 * user_prec * user_recall) / (user_prec + user_recall)\n",
    "            f1_list.append(user_f1)\n",
    "\n",
    "    final_acc = float(sum(total_acc_list)/len(total_acc_list))\n",
    "    \n",
    "    if(precision_list):\n",
    "        final_prec = float(sum(precision_list)/len(precision_list))\n",
    "    if(recall_list):\n",
    "        final_recall = float(sum(recall_list)/len(recall_list))\n",
    "    if(f1_list):\n",
    "        final_f1 = float(sum(f1_list)/len(f1_list))\n",
    "    \n",
    "    return (final_acc,final_prec,final_recall,final_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining some globals\n",
    "\n",
    "train_liked = train.loc[train['rating']!=1]\n",
    "test_liked = test.loc[test['recommend']==\"Yes\"]\n",
    "test_not_liked = test.loc[test['recommend']==\"No\"]\n",
    "\n",
    "k_friends=10\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1066, 300)\n",
      "(1066, 300)\n",
      "(1066, 300)\n",
      "(1066, 300)\n",
      "(1066, 300)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    accuracy_all = []\n",
    "    precision_all = []\n",
    "    recall_all = []\n",
    "    f1_all = []\n",
    "    \n",
    "    for i in range(5):\n",
    "\n",
    "        \"\"\"Train\"\"\"\n",
    "        train_category_id = i\n",
    "\n",
    "        #get category specific df\n",
    "        cat_ques_df = get_category_question_df(train_category_id,question_df)\n",
    "        qid_rowid_map = {v:k for k,v in enumerate(cat_ques_df['questionId'])}\n",
    "\n",
    "        #preprocess df\n",
    "        result_df = get_preprocessed_df(cat_ques_df,qid_rowid_map)\n",
    "\n",
    "        #tfidf matrix for all questions in a particular category\n",
    "        word2vec_matrix = get_word2vec_matrix(k,df)\n",
    "        print(word2vec_matrix.shape)\n",
    "        \n",
    "        #get user profile vectors\n",
    "        userid_row_map,profile_vector_mat = compute_user_profile_vectors([train_category_id],train_liked,user_df_dict,word2vec_matrix,qid_rowid_map)\n",
    "\n",
    "        #calculate similarity \n",
    "        similarity_matrix = compute_cosine_sim(profile_vector_mat)\n",
    "\n",
    "\n",
    "        #get top k friends\n",
    "        top_k_friends = top_k_similar_users(k_friends,similarity_matrix,userid_row_map)\n",
    "\n",
    "\n",
    "        accuracy_vals = []\n",
    "        precision_vals = []\n",
    "        recall_vals = []\n",
    "        f1_vals = []   \n",
    "\n",
    "        #Test\n",
    "\n",
    "        for j in range(5):\n",
    "\n",
    "            test_category_id = j\n",
    "\n",
    "            #get category specific items liked by users in the training set\n",
    "            train_user_liked_items = get_category_specific_user_rated_items([test_category_id],train_liked,user_df_dict)\n",
    "\n",
    "            #get top k friends recommendations based on test category\n",
    "            recommendations = get_category_specific_user_recommendations(top_k_friends,train_user_liked_items)\n",
    "\n",
    "            #liked items of those unique users {userid: liked_item}\n",
    "            test_user_liked_items = get_category_specific_user_rated_items([test_category_id],test_liked,user_df_dict)\n",
    "\n",
    "            #not liked items of those unique users {userid: not_liked}\n",
    "            test_not_liked_items = get_category_specific_user_rated_items([test_category_id],test_not_liked,user_df_dict)\n",
    "\n",
    "\n",
    "            #get recommendations of top k friends for each user in unique users in test set and compute accuracy\n",
    "            (accuracy,precision,recall,f1) = compute_accuracy(recommendations,test_user_liked_items,test_not_liked_items)\n",
    "            \n",
    "            accuracy_vals.append(accuracy)\n",
    "            precision_vals.append(precision)\n",
    "            recall_vals.append(recall)\n",
    "            f1_vals.append(f1)\n",
    "            \n",
    "        accuracy_all.append(accuracy_vals)\n",
    "        precision_all.append(precision_vals)\n",
    "        recall_all.append(recall_vals)\n",
    "        f1_all.append(f1_vals)          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51815222, 0.51410256, 0.47645503, 0.56160714, 0.50590476],\n",
       "       [0.56625175, 0.47820513, 0.48306878, 0.41121032, 0.433     ],\n",
       "       [0.56335866, 0.44871795, 0.61640212, 0.42371032, 0.39990476],\n",
       "       [0.50914281, 0.55897436, 0.48624339, 0.45019841, 0.46909524],\n",
       "       [0.60843734, 0.58076923, 0.46772487, 0.43700397, 0.38890476]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(accuracy_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No.of users liking questions in each category\n",
    "\n",
    "train_liked = train.loc[train['rating']==3]\n",
    "train_nopref = train.loc[train['rating']==2]\n",
    "train_notliked = train.loc[train['rating']==1]\n",
    "\n",
    "category_users_dict_liked = {}\n",
    "category_users_dict_nopref = {}\n",
    "category_users_dict_notliked = {}\n",
    "\n",
    "for i in range(5):\n",
    "    train_user_liked_items = get_category_specific_user_rated_items([i],train_liked,user_df_dict)\n",
    "    category_users_dict_liked[i] = len(train_user_liked_items)\n",
    "    \n",
    "for i in range(5):\n",
    "    train_user_nopref_items = get_category_specific_user_rated_items([i],train_nopref,user_df_dict)\n",
    "    category_users_dict_nopref[i] = len(train_user_nopref_items)\n",
    "    \n",
    "for i in range(5):\n",
    "    train_user_notliked_items = get_category_specific_user_rated_items([i],train_notliked,user_df_dict)\n",
    "    category_users_dict_notliked[i] = len(train_user_notliked_items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 26, 1: 22, 2: 22, 3: 25, 4: 25}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_users_dict_notliked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 29, 1: 28, 2: 28, 3: 29, 4: 29}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_users_dict_nopref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 24, 1: 18, 2: 24, 3: 19, 4: 22}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_users_dict_liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
